---
title: "LCExplore"
author: "Hoa Thuong Luu Phan (Carol Phan)"
date: "2/6/2019"
output: html_document
---
LENDING CLUB LOAN 

The dataset can be found [here](https://www.kaggle.com/wendykan/lending-club-loan-data/home). There are proxy 890,000 observations and 75 variables. The file contains all loans issued through the 2007-2015 with credit scores, delinquency, collections and many more.

Goals:

This project will examine the status of delinquency (response variable) of an account. Here we analyze the characteristics of various accounts that have indication of future delinquency.

Downloading the data from SQLite:

```{r}
#install.packages("RSQLite")
library("RSQLite")
#connect to SQLite
dataframe = "lending-club-loan-data/database.sqlite"
loan.sqlite = dbConnect(SQLite(),dbname=dataframe)
```

Exploring the data:

```{r}
#count the number of observations in the SQLite table
dbGetQuery(loan.sqlite,'select count(*) from loan') 
#get the 'loan' table as a dataframe
#notice that loan.sql includes index 
loan.sql = dbGetQuery(loan.sqlite,'select * from loan') 
#list of variables 
names(loan.sql)
#structure of the data
str(loan.sql)
#examples
head(loan.sql,5)
#t(filter(loan.sql,id==1077501))

## BMB: why do this???
loan.sql[is.na(loan.sql)]<- 999999999
```

Generate summaries of the data:


```{r}
library("dplyr")
library("ggplot2")
#looking at total loan amounts (in thousand) and return on investment per loan_status
loan_status = dbGetQuery(loan.sqlite,'select loan_status, count(*), sum(loan_amnt)/count(*), sum((total_pymnt/funded_amnt) * 100)/count(*) from loan GROUP BY loan_status')
loan_status=loan_status[-1,]
loan_status

ggplot(data=loan_status,aes(loan_status,`sum(loan_amnt)/count(*)`,size=`count(*)`))+geom_point(colour="blue")+theme(axis.text.x = element_text(angle=40,hjust=1))+labs(x='Status of the Loan',y='Average Loan Issued ($)',title='Average Loan Issued Grouped by Status',size='# of Accounts')

ggplot(data=loan_status,aes(loan_status,`sum((total_pymnt/funded_amnt) * 100)/count(*)`,size=`sum(loan_amnt)/count(*)`))+geom_point(colour="red")+theme(axis.text.x = element_text(angle=40,hjust=1))+labs(x='Status of the Loan',y='Average ROI (%)',title='Average ROI (%) Grouped by Status',size='Average Loan Issued ($)')

```

Next, we look at the loan issued across the USA:

```{r}
state = dbGetQuery(loan.sqlite,'select addr_state,count(*), sum(loan_amnt)/count(*) from loan GROUP BY addr_state')
state=state[-1,]
state
ggplot(data=state,aes(addr_state,`sum(loan_amnt)/count(*)`,size=`count(*)`))+geom_point(colour="purple")+theme(axis.text.x = element_text(angle=90,hjust=1))+labs(x='Provinces of USA',y='Average Loan Issued ($)',title='Average Loan Issued across USA',size='# of Accounts')
```

We are going to quickly look at:

```{r}
terms = dbGetQuery(loan.sqlite,'select loan_status,term,count(*),sum(int_rate)/count(*) from loan GROUP BY loan_status,term')

purpose = dbGetQuery(loan.sqlite,'select purpose, count(*) from loan GROUP BY purpose')

owner = dbGetQuery(loan.sqlite,'select home_ownership, count(*) from loan GROUP BY home_ownership')

empl = dbGetQuery(loan.sqlite,'select emp_length, count(*) from loan GROUP BY emp_length')

empt = dbGetQuery(loan.sqlite,'select emp_title, count(*) from loan GROUP BY emp_title')

#quantile buckets
#loan.current = filter(loan.sql,loan_status=='Current')
#bin = quantile(loan.current$annual_inc, seq(0,1,0.1))
#lab = c(0, prettyNum(bin[2:10], big.mark = ","), "+inf")
#lab = paste(lab[1:10], lab[2:11], sep = "-")
#loan.current = mutate(loan.current, annual_inc_bin = #cut(loan.current$annual_inc, breaks = bin, labels = factor(lab), include.lowest=TRUE))

#head(loan.current,5)

terms
purpose
owner
empl
empt

```

We are going to avoid data-snooping around delinquency related variables 

Generate training set and test set:

```{r}
#drop the first column and set to loan
loan = loan.sql[,-1]
#make the results reproducible
set.seed(1)
#set the training set
train = sample(887383,443690)
#set the test set
test = (-train) 
#split the loan data based on the training set
loantrain = loan[train,]
#splot the loan data based in the test set 
loantest = loan[test,]

#View(loantrain)
#make the results reproducible
set.seed(1)
#fit the linear model
#get the summary of the linear model 
#the test error of linear model using least square 
#problem: cannot lm 75 variables 

#get the y from training set
y = loantrain$delinq_2yrs
#get a matrix of training set
#x = model.matrix(delinq_2yrs~.,data=loantrain)

#Principal Component Analysis (PCA)
#pca = pcromp(,scale=FALSE)
#nlevels(loantrain$recoveries)
```

Conclusion:
- The status of the loan, 'Current', has the highest number of accounts with a high average loan issued 
- 'Does not meet the credit policy. Status:Fully Paid' borrowers have the highest average ROI, but they have the smallest average loan issued
- The number of payments on the loan correlates with the interest rate, i.e., 60 months of payments tend to have higher interest rate of approx. 18 percent than 30 months of payments with interest rate of approx. 13 percent
- The average loan issued is approx. $14,000 across the provinces of USA, with California (CA) has the highest number of accounts
- Approx. 524,000 (60%) borrowers requested the loan for debt consolidation 


Next step...
- Build a delinquency model
- Find relevant predictors by the Principal Component Analysis (PCA)
- Generate MSE plot on cross-validation from sample() function
- Get model.matrix() to work to get a matrix of training set 
          - Get the grid parameter for lambda
          - create the model for lasso model


Dealing with "..applied only to factors with 2 or more levels" error:
When divided into train/test sets, some of categorical variables ended up with only a single variable.
(1) do stratified/balanced splitting ("caret" package)
(2) lump rare factor levels ("forcats" package)
(3) throw away input variables that are very unbalanced 

```{r}
#summarize all of factor variables and look at the distribution of number of observations across levels to decide (1), (2) or (3)
#convert all character input variables to factors
loantrain <- loantrain %>%
  mutate_if(sapply(loantrain, is.character),as.factor)
sapply(loantrain, class)
summary(loantrain)

loantrain.char = loantrain[,sapply(loantrain, class)=='factor']
loantrain.num = loantrain[,sapply(loantrain, class)=='numeric']

length(loantrain.char)
length(loantrain.num)

#head(loantrain.char,5)
summary(loantrain.char)

#install.packages("devtools")
#devtools::install_github("ropenscilabs/skimr",force = TRUE)
#summary(loantrain)
library(skimr) 
#url, desc and id are removed from the data frame (unique for each obs)
loantrain.char <- select(loantrain.char,-c(url,desc,id))
skim(loantrain.char) #this may take awhile to load 
#verification_status_joint has 443403 NA's
#pymnt_plan only have 5 'y' obs
#application_type has 443401 IND obs 
loantrain.char <- select(loantrain.char,-c(verification_status_joint,pymnt_plan,application_type))

#we are going to take a look at continuous input variables
#head(loantrain.num,5)
summary(loantrain.num)
#Error in UseMethod("mean") : no applicable method for 'mean' applied to an object of class "c('double', 'numeric')
#skim(loantrain.num)

#drop member_id 
#variables with more than 400,000 obs Nas:
#inq_last_12m
#total_cu_tl
#inq_fi
#all_util
#max_bal_bc
#open_rv_24m
#open_rv_12m
#il_util
#total_bal_il
#mths_since_rcnt_il
#open_il_24m
#open_il_12m
#open_il_6m
#open_acc_6m
#dti_joint
#annual_inc_joint

#total of 16 variables...
#validate this by sql or manually pivot in Excel to count number of Na's

#NA is equivalent to 'blank' in the raw dataset, it could mean missing data OR ... (e.g. NA in annual_inc_joint because the type of account is not joint so this is not missing data; get rid of this column or fill Nas with 0s)

#right now drop it 
loantrain.num <- select(loantrain.num,-c(member_id,
                                         inq_last_12m,
                                         total_cu_tl,
                                         inq_fi,
                                         all_util,
                                         max_bal_bc,
                                         open_rv_24m,
                                         open_rv_12m,
                                         il_util,
                                         total_bal_il,
                                         mths_since_rcnt_il,
                                         open_il_24m,
                                         open_il_12m,
                                         open_il_6m,
                                         open_acc_6m,
                                         dti_joint,
                                         annual_inc_joint))

summary(loantrain.num)

#going back to categorical variables 
#check loantrain and loantest have same number of levels as original data

```

Principal Components Analysis (PCA)

```{r}
#drop variables that are related to delinquency:
#delinq_2yrs
#mths_since_last_delinq
#acc_now_delinq
loantrain.num.pca <- select(loantrain.num,-c(delinq_2yrs,mths_since_last_delinq,acc_now_delinq))

#Error in svd(x, nu = 0) : infinite or missing values in 'x'
#prcomp(loantrain.num)

#replace missing values with column means
for(i in 1:ncol(loantrain.num.pca)){
  loantrain.num.pca[is.na(loantrain.num.pca[,i]), i] <- mean(loantrain.num.pca[,i], na.rm = TRUE)
}
head(loantrain.num.pca,5)

prcomp(loantrain.num.pca) #works but inappropriate
#prcomp(loantrain.num,scale.=TRUE)
#Error in prcomp.default(loantrain.num, scale. = TRUE) : cannot rescale a constant/zero column to unit variance
#identify the zero-variance column
which(apply(loantrain.num.pca, 2, var)==0)
#remove zero variance columns
loantrain.num.pca2<-loantrain.num.pca[,apply(loantrain.num.pca, 2, var)!=0]
#check
#str(loantrain.num.pca2)
pca<-prcomp(loantrain.num.pca2,scale=TRUE)
pca
summary(pca)

#interpretation:




#we are going to do pca for numeric input variables
#https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues
#pca looks for properties that show as much variation across data
#pca looks for properties that allow to reconstruct the original characteristics as well as possible

```


Simple lm():
```{r}
#str(loantrain.char)
#str(loantrain.num)
lm(delinq_2yrs~.,data=loantrain.num)
#using type = "numeric" with a factor response will be ignoredError in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : contrasts can be applied only to factors with 2 or more levels
#lm(loan_status~.,data=loantrain.char)
#skim(loantrain.char)
str(loantrain.char)
#all categorical variables have 2 or more n_unique...
#let's do this manually...
#find the number of levels of factor variables 
ifelse(n <- sapply(loantrain.char, function(x) length(levels(x))) == 1, "DROP", "NODROP")
#there is no need to drop variables, what is the problem...
#CANNOT USE A LINEAR REGRESSION MODEL WITH A FACTOR AS RESPONSE VARIABLE

loantrain.new <- select(loantrain,-c(url,
                                     desc,
                                     id,
                                     verification_status_joint,
                                     pymnt_plan,
                                     application_type,member_id,
                                     inq_last_12m,
                                     total_cu_tl,
                                     inq_fi,
                                     all_util,
                                     max_bal_bc,
                                     open_rv_24m,
                                     open_rv_12m,
                                     il_util,
                                     total_bal_il,
                                     mths_since_rcnt_il,
                                     open_il_24m,
                                     open_il_12m,
                                     open_il_6m,
                                     open_acc_6m,
                                     dti_joint,
                                     annual_inc_joint,
                                     policy_code
                                     ))
str(loantrain.new)
#again, replace NAs with column means (only continuous variables)

lm(delinq_2yrs~.,data=loantrain.new) #very slow but working...
```
