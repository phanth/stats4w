---
title: "Lendingâ€™s Club Data"
author: "Hoa Thuong Luu Phan (Carol Phan)"
date: "2/5/2019"
output:
  html_document:
    df_print: paged
---

```{r}
## BMB: NO ABSOLUTE PATHNAMES PLEASE
## use a project, or switch your working directory
## see https://www.tidyverse.org/articles/2017/12/workflow-vs-script/
##
library("RSQLite")
library("dplyr")
library("ggplot2")
library("dbplyr")

## data downloaded from https://www.kaggle.com/wendykan/lending-club-loan-data

## loan <- read.csv("loan.csv")

#connect to SQLite
dataframe = "database.sqlite"
loan.sqlite = dbConnect(SQLite(),dbname=dataframe)
#get a list of all tables 
tables = dbListTables(loan.sqlite)
#count the number of observations in the SQLite tablep
pop = dbGetQuery(loan.sqlite,'select count(*) from loan') 
##get the 'loan' table as a dataframe
## BMB: do you really want to get the whole thing as
##  a data frame? better to wait and take only the pieces you want
##  (e.g. only test set or only training set)
loan.sql = dbGetQuery(loan.sqlite,'select * from loan')

## str(loan.sql)
## names(loan.sql)
## head(loan.sql,5)
## t(filter(loan.sql,id==1077501))
#Notice that loan.sql includes index 

## BMB: redefining 'pop' here? all distinct ids, so same value ...
pop=dbGetQuery(loan.sqlite,'select count(distinct(id)) from loan')
dbGetQuery(loan.sqlite,'select count(distinct(member_id)) from loan')

## explain what you're doing here?
## (average loan amounts in $1000 by status)
loan_status = dbGetQuery(loan.sqlite,
   'select loan_status, count(*), sum(loan_amnt)/(1000*count(*)) from loan \
GROUP BY loan_status')
state = dbGetQuery(loan.sqlite,'select addr_state, count(*), sum(loan_amnt)/(1000*count(*)) from loan GROUP BY addr_state')
purpose = dbGetQuery(loan.sqlite,'select purpose, count(purpose) from loan GROUP BY purpose')
dq = dbGetQuery(loan.sqlite,'select delinq_2yrs, count(id) from loan GROUP BY delinq_2yrs')
cur_dq = dbGetQuery(loan.sqlite,'select count(*) from loan where acc_now_delinq == 1')
terms = dbGetQuery(loan.sqlite,'select term, count(id) from loan GROUP BY term')
dq1 = dbGetQuery(loan.sqlite,'select mths_since_last_delinq, count(*) from loan GROUP BY mths_since_last_delinq')

loan.sqlite %>%
    tbl("loan") %>%
    select(loan_status) %>%
    summarise(m=median(loan_status))

 
loan_status2 = (loan.sqlite
    %>% tbl("loan")
    %>% select(loan_status,loan_amnt)
    %>% group_by(loan_status)
    %>% summarise(count=n(), avg_loan=mean(loan_amnt)/1000)
)
show_query(loan_status2)
loan_status2C <- collect(loan_status2)


#plots/tables
ggplot(data=loan_status[-1,],aes(loan_status,`sum(loan_amnt)/(1000*count(*))`,
                                 size=`count(*)`))+
    geom_point(colour="blue")+
    theme(axis.text.x = element_text(angle=90,hjust=1))+
    labs(y='Average Loan Amount in Thousand',
         title='Loan Status',size='# of Accounts')
## BMB: I'd suggest


loan_status2C %>%
    mutate(loan_status=reorder(loan_status,avg_loan)) %>%
    na.omit() %>%
ggplot(aes(loan_status,avg_loan,size=count/1000))+
    geom_point(colour="blue")+
    labs(y='Average Loan Amount ($1000)',x="",
         title='Loan Status',size='# of Accounts (thousands)')+
    coord_flip()

ggplot(data=state[-1,],aes(addr_state,`sum(loan_amnt)/(1000*count(*))`,size=`count(*)`))+geom_point(colour="red")+theme(axis.text.x = element_text(angle=90,hjust=1))+labs(y='Average Loan Amount in Thousand',title='USA',size='# of Accounts',x='States')
purpose 
terms

#drop the first column and set to loan
loan = loan.sql[,-1]
#make the results reproducible
set.seed(1)
##set the training set
## BMB: shouldn't use raw numbers. Something more like
ntot <- pull(pop)  ## pull() extracts a column from a tibble
train <- sample(ntot,round(0.5*ntot))
## train = sample(887383,443690)
#set the test set
test = (-train) 
#split the loan data based on the training set
loantrain = loan[train,]
#splot the loan data based in the test set 
loantest = loan[test,]

## BMB: worth looking for a way to subset the data inside the
##  database?
#View(loantrain)
#make the results reproducible
set.seed(1)
#fit the linear model
#get the summary of the linear model 
#the test error of linear model using least square 
#problem: cannot lm 75 variables 

#get the y from training set
y = loantrain$delinq_2yrs
#get a matrix of training set
x = model.matrix(delinq_2yrs~.,data=loantrain)

#Principal Component Analysis (PCA)
#pca = prcomp(,scale=FALSE)
#nlevels(loantrain$recoveries)


```
Next step...

- Find relevant predictors by the Principal Component Analysis (PCA)
- Generate MSE plot on cross-validation from `sample()` function
- Get `model.matrix()` to work to get a matrix of training set 
          - Get the grid parameter for lambda
          - create the model for lasso model





